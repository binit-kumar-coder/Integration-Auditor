# üöÄ Complete File Upload API - Integration Auditor

## ‚úÖ **Enterprise File Upload Implementation Complete**

You were absolutely right! I've now implemented comprehensive file upload APIs that handle:

- ‚úÖ **Gigabyte-sized CSV files** (up to 10GB per file)
- ‚úÖ **Multiple tiers** (tier1, tier2, tier3)
- ‚úÖ **Multiple CSV types** per tier (integrations, imports, exports, flows, connections)
- ‚úÖ **Chunked uploads** for very large files
- ‚úÖ **Batch uploads** for multiple files
- ‚úÖ **File validation** and management

## üìã **Complete File Upload API Endpoints**

### **üîÑ Single File Upload**
```
POST /api/files/upload/tier/{tier}
```
**Supports:** Up to 10GB single file upload
**Usage:**
```bash
curl -X POST http://localhost:3001/api/files/upload/tier/tier1 \
  -F "csvFile=@integrations.csv" \
  -F "csvType=integrations"
```

### **üì¶ Batch File Upload**
```
POST /api/files/upload/tier/{tier}/batch
```
**Supports:** Multiple CSV files in one request
**Usage:**
```bash
curl -X POST http://localhost:3001/api/files/upload/tier/tier1/batch \
  -F "csvFiles=@integrations.csv" \
  -F "csvFiles=@imports.csv" \
  -F "csvFiles=@exports.csv" \
  -F "csvFiles=@flows.csv" \
  -F "csvFiles=@connections.csv"
```

### **üîÄ Chunked Upload (For GB+ Files)**

#### **1. Start Chunked Upload:**
```
POST /api/files/chunked-upload/start
```
```bash
curl -X POST http://localhost:3001/api/files/chunked-upload/start \
  -H "Content-Type: application/json" \
  -d '{
    "filename": "large-integrations.csv",
    "fileSize": 5368709120,
    "csvType": "integrations", 
    "tier": "tier1",
    "chunkSize": 10485760
  }'
```

#### **2. Upload Chunks:**
```
POST /api/files/chunked-upload/{uploadId}/chunk
```
```bash
# Upload each chunk
curl -X POST http://localhost:3001/api/files/chunked-upload/{uploadId}/chunk \
  -F "chunk=@chunk_000000" \
  -F "chunkNumber=0"
```

#### **3. Complete Upload:**
```
POST /api/files/chunked-upload/{uploadId}/complete
```
```bash
curl -X POST http://localhost:3001/api/files/chunked-upload/{uploadId}/complete
```

### **üìÇ File Management**

#### **List All Files:**
```
GET /api/files/list
GET /api/files/list?tier=tier1
```
```bash
# List all files across all tiers
curl http://localhost:3001/api/files/list

# List files for specific tier
curl http://localhost:3001/api/files/list?tier=tier1
```

#### **Get File Info:**
```
GET /api/files/tier/{tier}/csv/{csvType}
```
```bash
# Get integrations.csv info from tier1
curl http://localhost:3001/api/files/tier/tier1/csv/integrations
```

#### **Delete File:**
```
DELETE /api/files/tier/{tier}/csv/{csvType}
```
```bash
# Delete imports.csv from tier1
curl -X DELETE http://localhost:3001/api/files/tier/tier1/csv/imports
```

#### **Validate Tier Files:**
```
POST /api/files/validate/tier/{tier}
```
```bash
# Validate all CSV files in tier1
curl -X POST http://localhost:3001/api/files/validate/tier/tier1
```

## üéØ **Complete Workflow for Remote Upload**

### **Scenario 1: Upload Complete Tier Data (Small Files)**
```bash
# 1. Upload all CSV files for tier1 in batch
curl -X POST http://localhost:3001/api/files/upload/tier/tier1/batch \
  -F "csvFiles=@integrations.csv" \
  -F "csvFiles=@imports.csv" \
  -F "csvFiles=@exports.csv" \
  -F "csvFiles=@flows.csv" \
  -F "csvFiles=@connections.csv"

# 2. Validate uploaded files
curl -X POST http://localhost:3001/api/files/validate/tier/tier1

# 3. Run processing
curl -X POST http://localhost:3001/api/fix/dry-run \
  -H "Content-Type: application/json" \
  -d '{"edition": "premium", "tier": "tier1", "operatorId": "remote-user"}'
```

### **Scenario 2: Upload Large File (GB+ Size)**
```bash
# 1. Start chunked upload for 5GB integrations.csv
UPLOAD_RESPONSE=$(curl -X POST http://localhost:3001/api/files/chunked-upload/start \
  -H "Content-Type: application/json" \
  -d '{
    "filename": "large-integrations.csv",
    "fileSize": 5368709120,
    "csvType": "integrations",
    "tier": "tier1",
    "chunkSize": 10485760
  }')

UPLOAD_ID=$(echo $UPLOAD_RESPONSE | jq -r '.uploadId')

# 2. Upload chunks (example for first chunk)
curl -X POST http://localhost:3001/api/files/chunked-upload/$UPLOAD_ID/chunk \
  -F "chunk=@chunk_000000" \
  -F "chunkNumber=0"

# 3. Repeat for all chunks...

# 4. Complete upload
curl -X POST http://localhost:3001/api/files/chunked-upload/$UPLOAD_ID/complete

# 5. Validate and process
curl -X POST http://localhost:3001/api/files/validate/tier/tier1
```

### **Scenario 3: Manage Multiple Tiers**
```bash
# 1. Upload tier1 data
curl -X POST http://localhost:3001/api/files/upload/tier/tier1 \
  -F "csvFile=@tier1-integrations.csv" \
  -F "csvType=integrations"

# 2. Upload tier2 data  
curl -X POST http://localhost:3001/api/files/upload/tier/tier2 \
  -F "csvFile=@tier2-integrations.csv" \
  -F "csvType=integrations"

# 3. Upload tier3 data
curl -X POST http://localhost:3001/api/files/upload/tier/tier3 \
  -F "csvFile=@tier3-integrations.csv" \
  -F "csvType=integrations"

# 4. List all uploaded files
curl http://localhost:3001/api/files/list

# 5. Process each tier
curl -X POST http://localhost:3001/api/fix/dry-run \
  -H "Content-Type: application/json" \
  -d '{"edition": "premium", "tier": "tier1", "operatorId": "multi-tier-user"}'
```

## üéØ **Key Features**

### **‚úÖ Enterprise-Grade File Handling:**
- **10GB file size limit** per upload
- **Streaming uploads** for memory efficiency
- **Chunked upload support** for very large files
- **Progress tracking** for long uploads
- **File validation** and format checking
- **Automatic directory management**

### **‚úÖ Multi-Tier Support:**
- **tier1, tier2, tier3** support
- **Independent file management** per tier
- **Batch operations** across tiers
- **Tier-specific validation**

### **‚úÖ Complete CSV Type Support:**
- **integrations.csv** - Main integration data
- **imports.csv** - Import resource data  
- **exports.csv** - Export resource data
- **flows.csv** - Flow resource data
- **connections.csv** - Connection data

### **‚úÖ Production Features:**
- **File size formatting** (human-readable)
- **Upload progress tracking**
- **Error handling** and recovery
- **File metadata** and statistics
- **Cleanup of temporary files**

## üåê **Swagger Documentation**

All file upload endpoints are documented in the Swagger UI:
```
üåê Complete Documentation: http://localhost:3001/api/docs/
```

**File Upload Section includes:**
- **Single file upload** with size limits
- **Batch upload** for multiple files
- **Chunked upload** for GB+ files
- **File management** (list, info, delete)
- **Validation APIs** for file integrity

## üèÜ **Complete Remote Operation**

**The Integration Auditor now supports complete remote operation:**

1. ‚úÖ **Upload CSV files** via API (any size)
2. ‚úÖ **Manage multiple tiers** via API
3. ‚úÖ **Validate file integrity** via API
4. ‚úÖ **Process data** via API (all CLI commands)
5. ‚úÖ **Monitor progress** via API
6. ‚úÖ **Download results** via API

**No file system access needed - everything via REST API!**

Perfect for remote Docker deployment where only HTTP access is available! üöÄ
